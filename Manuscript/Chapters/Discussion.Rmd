---
title: "Creative or not, Discussion"
output:
  pdf_document: papaja::apa6_pdf
  html_document: default
  word_document: papaja::apa6_word
---
  In this paper, we aimed to study the cognitive basis of how people decide whether an idea is creative or not during divergent thinking. Divergent thinking is a two-phase process where people come up with ideas (ideation phase) and decide whether or not to use them [evaluation phase;  @Basadur:1995; @Guilford:1967; @RuncoBasadur:1993]. We focused on the evaluation phase and used Bayesian cognitive modeling to better understand it. Using a novel application of the drift diffusion model (DDM) we aimed to understand how people weigh the two components of creativity, originality and utility, when deciding whether an idea is creative or not. We used the Creative-or-Not (CON) task, a timed two-choice decision-making task, where people are presented with ideas of how to use an everyday object (e.g., use a book as a roof tile) and then decide whether these are creative or not. The CON-task stimuli varied on how original and how useful they were (e.g., using a book to read is useful, but not original, whereas using a book as roof tile can be both). This way we could estimate individual differences in how originality and utility implicitly contributed to people’s creativity judgements by examining their effect on the DDM drift rate parameter. The drift rate represents people’s tendency to respond “creative” or “not creative”. The higher its absolute value, the greater the accumulated evidence for creative-or-not decisions, and the faster the response. Our main findings were: (1) stimulus originality strongly influenced participants’ tendency towards creative responses (i.e., the drift rate), whereas stimulus utility was only somewhat related to it; (2) there were large individual differences in how much participants took the originality and utility of presented ideas into account (i.e., varying individual effects of stimulus originality and utility on the drift rate); (3) participants’ implicit tendencies or values of originality and utility on the CON-task were aligned with their self-reported importance ratings of originality and utility for creativity; (4) alternative uses task (AUT) scores for originality and utility coincided with how much the originality and utility of the presented CON-task idea weighed in on their decisions. We now discuss each of these results in more detail.  
  Our finding that people value originality when evaluating creativity, evidenced by a substantial overall effect of originality on DDM drift rates, are in line with previous studies showing that people associate originality more so than utility with creativity [e.g., @CaroffBesancon:2008; @DiedrichEtAl:2015; @RuncoCharles:1993]. In both studies, the utility of ideas was only somewhat related to participants' tendency towards creative responses. In earlier work we also see that utility, or one of its creative synonyms (e.g., appropriateness, value) is less valued when it comes to judging creativity [e.g., @DiedrichEtAl:2015]. However, despite the considerably smaller effect, a Bayesian model comparison supports our proposed model and suggests that utility matters when evaluating the creativity of ideas[^i]. Future work with the CON-task could include additional information about presented ideas, such as “surprise” [@Boden:2004] and “impact” [@SternbergLubart:1996], to examine how these components implicitly influence people’s creativity judgments.  
  Interestingly, just as researchers sometimes disagree on the definition of creativity [@Simonton:2018], the homogenous group of psychology students in our study also varied greatly in their conceptions of creativity. We found both quantitative and qualitative individual differences in how they valued originality and utility [@HaafRouder:2017; @HaafRouder:2018]. Originality was usually important, but a few people seemed to regard original stimuli “not creative”. Regarding utility, there were large individual differences too. Some participants seemed to value utility, a few rated any useful idea as “not creative”, and some appeared to disregard it entirely. Moreover, the implicit values were negatively correlated (although in Study 2 we partly attributed this association to the stimulus correlation): the more participants valued originality, the less they valued utility when judging creativity. Future research should look to generalize these results to other populations or types of creativity judgments. For example, adolescents appear to place more value on originality and less on utility [@Stevenson:2022], so there may be a developmental trend. Also, judging the creativity of AUT ideas is interesting as the task is used so often in psychological assessment and educational assessment [e.g., @BenedekEtAl:2016]. But, would the utility of an idea be considered more valuable in real-world situations, for example when judging the creativity of ideas to combat climate change?  
  After the CON-task, we asked participants to rate how important they thought originality and utility were for creativity. These self-reported relevance ratings more or less corresponded to their implicit values of originality and utility on the CON-task. For example, those who strongly and explicitly indicated that originality/innovativeness is important for creativity also tended to implicitly value originality in the CON-task. In addition, it appears that the CON-task provides an indirect way to tap into what people consider creative.  
  Similar to @CaroffBesancon:2008, our results also showed that the more participants took originality and utility into account on the CON-task, the more original and useful their responses to the AUT were. We cannot talk about causality, but it seems plausible that people’s implicit values of originality and utility influence what ideas they produce and how they evaluate and select ideas during divergent thinking, like on the AUT. This coincides with findings that the more creative someone is, the better their creativity judgements are, whether its of their own or other's ideas [e.g., @BenedekEtAl:2016; @Silvia:2008].

## Methodological Implications  
  To our knowledge, this is the first time a mathematical model such as the DDM has been applied to the evaluation phase of divergent thinking. The DDM is generally applied to timed two-choice decision tasks where there is clearly a correct answer, such as lexical decision tasks [e.g., @WagenmakersEtAl:2008]. Therefore, applying the DDM to the CON-task, where there is no correct answer and we are basically assessing what factors influence people’s tendency to decide if an idea is creative, is novel. Applying the DDM generally worked well on both studies, suggesting that the DDM might provide a reasonable account of the evaluation process in the AUT. A substantive interpretation of the evaluation process could be that when people judge creativity in the CON-task, they stochastically extract, accumulate, and integrate internal noisy signals about a stimulus' creativity, for example regarding the stimuli's originality and utility [for an interpretation regarding value-based decisions, see @MilosavljevicEtAl:2010].  
  Although overall we deemed the model fit to be acceptable, the model predicted slightly more right-skewed RT distributions at the individual level than there were in the data. This kind of misfit suggests that participants responded slower than the model predicted (but also note the predicted longer RTs in the upper quantiles of the RT distribution; see online supplementary materials). Since we explicitly instructed participants to respond as fast as possible, these longer RTs appear necessary for participants to evaluate creativity in the CON-task. The greater need for time is also reflected in a larger than usual boundary separation parameter which can be equated with the discrimination parameter in a 2PL model. It is directly influenced by the time participants have or take to respond [@vanderMaasEtAl:2011; @Wickelgren:1977]. Longer RTs therefore imply greater discriminatory power of the CON-task stimuli [@vanderMaasEtAl:2011], which is desirable given our aim to study individual differences in creativity conceptions. However, the relatively long RTs might also suggest that participants do not immediately make a decision once they cross a decision boundary. Participants might even cross the boundary more than once. But even if the underlying decision process truly consists of more than one single random walk and the DDM is too simplistic, the model might still be a good enough approximation of the evaluation process as many complex decision-making models boil down to the DDM [@BogaczEtAl:2006; @vanderMaasEtAl:2011].  
  Regarding the role of RTs in our two studies, decision speed did not vary much across stimulus originality and utility ratings. Accordingly, there was no inverted u- or v-shaped relationship between RTs and stimulus characteristics as one might have expected. At best, there was a tendency for stimuli with higher originality and utility ratings to be answered more slowly. A possible explanation is that the effects of originality and utility on the drift rate (i.e., people's tendency towards deciding “creative”) were negatively correlated in both studies. This means that the more participants valued originality, the less they valued utility and vice versa. There appears to be a trade-off where people balance one dimension against the other when judging creativity, which could explain why stimuli with both higher originality and utility were processed more slowly.  
  The lacking influence of RTs begs the question of whether the DDM is not overly complex for the CON-task data from our two studies. For example, a hierarchical probit analysis[^r] of our data resulted in similar conclusions. It would be interesting to examine whether RT effects are more apparent if participants are given less time (e.g., 3s versus the 9s in this study); especially since in the real-world people sometimes need to make split-second choices about which idea to pursue. Perhaps this would also lead to a better DDM model fit regarding the RT distribution. Also, instructions that emphasize speed more could affect the evaluation process, just as those of quantity or quality affect the ideation phase of divergent thinking [@Said-MetwalyEtAl:2020].  

## Conclusion
  This paper demonstrates a new approach to studying the evaluation process during divergent thinking. Our novel application of the drift diffusion model provides a mathematical method to study how people decide what’s creative. The results imply that it is important to take both originality and utility into account when examining how people judge creativity. Also, given how conceptions of creativity vary, our findings suggest that when assessing creativity using divergent thinking tasks like the AUT, managers or researchers should clarify what the rating criteria are to provide a fair playing field for all.

[^i]: We conducted a Bayesian model comparison using Bridge sampling [not pre-registered; @MengWong:1996] where we compare our original model to a model that has neither an overall nor a random utility effect on the drift rate. We found extreme evidence for our original model over the model without any utility effects. We report this analysis in the supplementary materials. We thank an anonymous reviewer for suggesting this analysis.    
[^r]: Exploratory, not pre-registered, see online supplementary materials  