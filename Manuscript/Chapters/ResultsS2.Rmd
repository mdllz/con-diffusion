---
title: "Creative or not, Results Study 2"
output:
  pdf_document: papaja::apa6_pdf
  html_document: default
  word_document: papaja::apa6_word
---

```{r 'Analysis S2', child = "../Analysis/Analysis2.Rmd"}
```

The hypotheses and analysis plan for Study 2 were preregistered before seeing the data. We employed the same exclusion criteria as in Study 1 (see Appendix B).

```{r 'plot with RTs', child = "../Figures/RTfigure.Rmd"}

```

  The descriptives were very similar to Study 1. The mean RT across participants and trials was `r mean(dat2$rt)` s and the median `r median(dat2$rt)` s ($SD =$ `r sd(dat2$rt)`). The overall RT distribution is shown in Appendix C. The overall proportion of 'creative' responses was `r mean(dat2$creative)`. The mean RT for 'creative' responses was `r mean(dat2[dat2$creative == 1,]$rt)` s ($SD =$ `r sd(dat2[dat2$creative == 1,]$rt)`). For 'not creative' responses, this was `r mean(dat2[dat2$creative == 0,]$rt)` s ($SD =$ `r sd(dat2[dat2$creative == 0,]$rt)`). Stimuli with higher scores on originality and utility were again answered more slowly (see Figures \@ref(fig:plotRT)C). A Bayesian correlation analysis with median-split data suggested weak evidence for a correlation between RT and originality in the high-utility group, $r =$ `r mean(corr_median_split_s2_util_high_incl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s2_util_high_incl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s2_util_high_incl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s2_util_high_incl_median)$full_result`, and also weak evidence for no association between originality and RT in the low-utility group[^k], $r =$ `r mean(corr_median_split_s2_util_low_incl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s2_util_low_incl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s2_util_low_incl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s2_util_low_incl_median)$full_result`. Furthermore, as in Study 1, Figure \@ref(fig:plotRT)D and a Bayesian paired t-test analysis suggested that participants, on average, responded equally fast when they answered 'not creative', ($M =$ `r mean(t_test_S2$not_creative)` s, $SD =$ `r sd(t_test_S2$not_creative)` s), as opposed to 'creative' $M =$ `r mean(t_test_S2$creative)` s, $SD =$ `r sd(t_test_S2$creative)` s, `r apa_print(bf_rt_response_s2)$statistic`.  
  

  
### Model Fit
  
  In contrast to Study 1, we used informative priors for the stimulus originality and utility effects on the drift rate, based on Study 1's estimation results. Specifically, we specified truncated normal distributions as priors for $\mu_{\theta_{OR}}$, and $\mu_{\theta_{UT}}$,
\[\mu_{\theta_{OR}}, \mu_{\theta_{UT}} \sim \mbox{Normal}^+(0,0.2),\].  
All remaining priors were the same as in Study 1 except for $\beta$ (see Appendix A). We again fitted the model using the R package *brms* [@Burkner:2018],  ran `r chains2` chains with `r iter2` iterations of which `r warmup2`  iterations per chain were used as warmup, leaving us with `r (chains2*iter2) - (chains2*warmup2)` iterations to base the analysis on.  
  We again inspected the model diagnostics and model fit. There were no signs of non-convergence, with `r nr.div.trans2` divergent transitions, and $\hat{R}$ values below 1.01 [@VehtariEtAl:2020]. Moreover, we again assessed the model fit using posterior predictive checks. The model fit was similar as in Study 1 and overall acceptable (see the online supplementary material). As a robustness check, we also re-estimated the model including participants that we excluded based on exclusion criterion 3 (fewer than 47 remaining trials; see the online supplementary materials). 
  
### Modeling Results

Summary statistics of the estimated model parameters are shown in Table \@ref(tab:resFEtable) and \@ref(tab:resREtable). A table with the correlations among the random effects can be found in Appendix B. Overall, the estimated DDM parameters were very similar to the ones in Study 1.

```{r 'fixed effects table', child = "../Tables/FEtable.Rmd"}

```

```{r 'random effects table', child = "../Tables/REtable.Rmd"}

```

### Hypotheses testing

To test our hypotheses, we used the Savage-Dickey method [@Dickey:1971] of approximating Bayes factors. In this method, the Bayes factor is computed by a ratio of the prior and posterior density at the value zero. Assessing H1, we computed a Bayes factor comparing how well the hypothesis of a positive effect of stimulus originality on the drift rate predicted the data in comparison to the null hypothesis. All posterior samples were greater than zero. Therefore, the evidence in favor of H1 can be regarded as greater than `r (chains2*iter2) - (chains2*warmup2)`. In contrast, there was mere anecdotal evidence for an effect of utility on the drift rate, the Bayes factor was `r 1/h2$hypothesis$Evid.Ratio`. This means that the data was `r 1/h2$hypothesis$Evid.Ratio` times more likely to have occurred under H2 than under the null hypothesis. Not suprisingly, the Bayes factor for H3 that the overall effect of stimulus originality is greater than the effect of stimulus utility (rather than the other way around), was again greater than `r (chains2*iter2) - (chains2*warmup2)`.      
  We examined the correlation between the stimulus originality and utility effects on the drift rate (H4). The random effects correlation as estimated by the model, $\rho_{\sigma_{\theta_{OR}}\sigma_{\theta_{UT}}}$, had a posterior mean of `r  REsummary2[8,1]`, 95%CrI  [$`r REsummary2[8,3]`, `r REsummary2[8,4]`$], and the correlation based on the individual posterior means was $r =$ `r mean(h4.samples[,1])` 95%CrI  [`r quantile(h4.samples[,1], probs = 0.025)`, `r quantile(h4.samples[,1], probs = 0.975)`]`r apa_print(h4)$full_result[1]`. We again explored the robustness of the correlation between the originality and utility effects on the drift rate and by estimating the DDM based on data from a subset of weakly correlated stimuli (see Study 1)[^Ã®]. Unlike in Study 1, the correlation between the effects became considerably smaller. The posterior mean of the correlation was reduced to the size of the stimulus correlation in the reduced item pool ($r =$ -.17), suggesting that the negative correlation between originality and utility stimulus effects on the drift rate was not as robust as in Study 1.   
  The individual differences were again reflected in the variability parameters of the originality and utility effects on the drift rate. The posterior mean of the variability parameters for $\sigma_{OR}$ was `r REsummary2[2,1]` and for $\sigma_{UT}$ this was also `r REsummary2[3,1]`. The Savage-Dickey density ratio cannot be used to compute a Bayes factor quantifying the evidence for individual variability. However, the 95% credible intervals of both variability parameters did not include zero, supporting H5a and H6a that the variability was substantial. To further examine the extent of individual variation, we again plotted individual posterior means and credible intervals in increasing order (see Figures \@ref(fig:plotIndEstimates)C and D). Regarding originality, the CrI of `r orig.dr.sums2[1,3]` individuals included zero (`r round(sum(eff2$Q2.5.orig.rating_s < 0 & eff2$Q97.5.orig.rating_s > 0)/nrow(eff2)*100, digits = 2)`%) indicating that some individuals' drift rates were only weakly (if at all) determined by the stimuli's originality. Out of these participants, there were even `r orig.dr.sums2[1,4]` participants with a negative posterior mean (`r round(sum(eff2$Estimate.orig.rating_s < 0)/nrow(eff2)*100, digits = 2)`%). Participants also again differed in their utility slopes. The majority of the individual CrIs (*n* = `r util.dr.sums2[1,3]`; `r round(sum(eff2$Q2.5.util.rating_s < 0 & eff2$Q97.5.util.rating_s > 0)/nrow(eff2)*100, digits = 2)`%) included zero, `r util.dr.sums2[1,1]` (`r round(sum(eff2$Q2.5.util.rating_s > 0), digits = 2)/nrow(eff2)*100`%) of them excluded and were above zero, and `r util.dr.sums2[1,2]` (`r round(sum(eff2$Q97.5.util.rating_s < 0), digits = 2)/nrow(eff2)*100`%) individual CrIs excluded and were below zero.  
  
```{r 'plot with IndDiffs', child = "../Figures/Individual_estimates.Rmd"}

```

 In line with Haaf and Rouder (2017, 2018), we tested the hypothesis that all individuals have a positive effect of stimulus originality on the drift rate using the encompassing prior approach [H5b; @KlugkistEtAl:2005; @KlugkistHoijtink:2007]. Here, we compared the predictive accuracy of the hypothesis that everyone's originality slope is positive to the hypothesis that originality effects can be positive, zero or negative. The constraint that everyone has a positive effect was not fulfilled in any of the iterations. Therefore, the Bayes factor for the latter, unconstrained hypothesis can be considered at least `r BF.H5b`, (assuming that the next iteration might be the first in favor of the ordinal constraint) suggesting that not everyone has a positive originality effect on the drift rate. Regarding the individual utility effects, we tested the hypothesis that some individuals have a positive effect of stimulus utility on the drift rate, some have a negative effect, and some have no effect (H6b). Here, the data provided overwhelming support for the unconstrained hypothesis H6b over the hypothesis that everyone has a positive utility effect as the Bayes factor was again at least `r BF.H6b` (assuming that the next iteration might be the first in favor of the ordinal constraint).  
 
#### CON-task and self-report ratings of originality and utility

  To test the hypothesis that stimulus originality and utility effects on the drift rate were positively correlated with self-reported importance ratings of originality and utility, respectively (H7a and b), we conducted one-sided Bayesian correlation tests again using sum scores. There was a positive correlation between the originality sum scores and the individual originality effects, $r =$ `r mean(h7a.samples[,1])`, 95%CrI  [`r quantile(h7a.samples[,1], probs = 0.025)`, `r quantile(h7a.samples[,1], probs = 0.975)`]`r apa_print(h7a)$full_result[1]` as well as a positive correlation between the utility sum scores and the individual utility effects, $r =$ `r mean(h7b.samples[,1])`, 95%CrI  [`r quantile(h7b.samples[,1], probs = 0.025)`, `r quantile(h7b.samples[,1], probs = 0.975)`]`r apa_print(h7b)$full_result[1]`, supporting both H7a and H7b. We again conducted an exploratory cluster analysis on the individual posterior means (see Figure \@ref(fig:corOrigUtil)), which yielded practically the same result as in Study 1[^u].     
  
```{r 'plot with correlations', child = "../Figures/Cor_orig_util.Rmd"}

```

#### CON-task and divergent thinking

  To examine associations between the stimulus originality and utility effects on the drift rate and creative performance (H8 and H9), we followed the same data cleaning procedures as described in Study 1. Since we had directed hypotheses, we used one-sided correlation tests. There was a positive correlation between the stimulus originality effects and the AUT originality scores, $r =$ `r mean(h8a.samples[,1])`, 95%CrI  [`r quantile(h8a.samples[,1], probs = 0.025)`, `r quantile(h8a.samples[,1], probs = 0.975)`]`r apa_print(h8a)$full_result[1]`. However, there was no evidence for a correlation between AUT originality scores and the stimulus utility effects from the CON-task, $r =$ `r mean(h8b.samples[,1])`, 95%CrI  [`r quantile(h8b.samples[,1], probs = 0.025)`, `r quantile(h8b.samples[,1], probs = 0.975)`]`r apa_print(h8b)$full_result[1]` (H8b). Moreover, we considered the evidence to be inconclusive as the data were only `r 1/exp(h8b@bayesFactor$bf)[1]` times more likely to have occured under the null hypothesis rather than hypothesis H8b. Furthermore, there was a positive correlation between the AUT utility scores and the stimulus utility effects, $r =$ `r mean(h9a.samples[,1])`, 95%CrI [`r quantile(h9a.samples[,1], probs = 0.025)`, `r quantile(h9a.samples[,1], probs = 0.975)`]`r apa_print(h9a)$full_result[1]` (H9a), and a negative correlation between the AUT utility scores and the stimulus originality effects on the drift rate, $r =$ `r mean(h9b.samples[,1])`, 95%CrI  [`r quantile(h9b.samples[,1], probs = 0.025)`, `r quantile(h9b.samples[,1], probs = 0.975)`]`r apa_print(h9b)$full_result[1]` (H9b).  
  
[^Ã®]: This analysis was not pre-registered.
[^u]: This analysis was not pre-registered.
[^k]: The exact results again depended on whether the median of the stimuli's utility ratings was included in the low- or the high-utility group. When the median was assigned to the low-utility group, the evidence for the correlation between originality and RT in the high-utility group was even smaller: $r =$ `r mean(corr_median_split_s2_util_high_excl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s2_util_high_excl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s2_util_high_excl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s2_util_high_excl_median)$full_result`. However, the Bayes factor in favor of no correlation between originality and RT in the low-utility group was slightly bigger, $r =$ `r mean(corr_median_split_s2_util_low_excl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s2_util_low_excl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s2_util_low_excl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s2_util_low_excl_median)$full_result`    