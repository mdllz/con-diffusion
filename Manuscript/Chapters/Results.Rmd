---
title: "Creative or not, Results Study 1"
output:
  pdf_document: papaja::apa6_pdf
  html_document: default
  word_document: papaja::apa6_word
---

```{r 'Analysis S1', child = "../Analysis/Analysis.Rmd"}
```

  The data cleaning is described in Appendix B. The cleaned dataset comprised `r length(unique(dat1$pers))` participants and `r nrow(dat1)` trials.  The mean RT across participants and trials after excluding data was `r mean(dat1$rt)` seconds ($Median =$ `r median(dat1$rt)`, $SD =$ `r sd(dat1$rt)`). The overall RT distribution is shown in Appendix C. The overall percentage of 'creative' responses was `r mean(dat1$creative)*100`%. The mean RT for 'creative' responses across participants and trials was `r mean(dat1[dat1$creative == 1,]$rt)` s ($SD =$ `r sd(dat1[dat1$creative == 1,]$rt)`), and `r mean(dat1[dat1$creative == 0,]$rt)` s ($SD =$ `r sd(dat1[dat1$creative == 0,]$rt)`) for 'not creative' responses. Figure \@ref(fig:plotRT)A shows that RTs for some stimuli were longer than for others. A Bayesian correlation analysis with median-split stimulus data suggested weak evidence for a correlation between RT and originality in the high-utility stimulus group, $r =$ `r mean(corr_median_split_s1_util_high_incl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s1_util_high_incl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s1_util_high_incl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s1_util_high_incl_median)$full_result`, and anecdotal evidence for no relationship between originality and RT in the low-utility stimulus group[^d], $r =$ `r mean(corr_median_split_s1_util_low_incl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s1_util_low_incl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s1_util_low_incl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s1_util_low_incl_median)$full_result` (see Figure \@ref(fig:plotRT)A). Furthermore, Figure \@ref(fig:plotRT)B and a Bayesian paired t-test analysis suggested that participants, on average, responded equally fast with 'not creative', $M =$ `r mean(t_test_S1$not_creative)` s, $SD =$ `r sd(t_test_S1$not_creative)` s, as opposed to 'creative' $M =$ `r mean(t_test_S1$creative)` s, $SD =$ `r sd(t_test_S1$creative)` s, `r apa_print(bf_rt_response_s1)$statistic`.  

### Model Fit
  
  We fitted the DDM using the R package *brms* [@Burkner:2018] which works with Stan to draw samples from the posterior distribution of Bayesian models [@CarpenterEtAl:2017]. We ran `r chains1` chains with `r iter1` iterations each. `r warmup1` iterations per chain were used as warmup to adapt the sampler. Consequently, our analyses were based on a total of `r  (chains1*iter1)-(chains1*warmup1)` iterations.[^w]  
  We decided to not allow the bias parameter $\beta$ to vary across individuals because when we did, the random effects of the bias and drift rate intercept were highly correlated, suggesting identifiability issues. We therefore estimated the DDM with only a population-level bias parameter. The remaining DDM parameters were not affected by this change.   
  We performed several model diagnostics procedures and inspected the model fit. There were no signs of non-convergence, with `r nr.div.trans1` divergent transitions and $\hat{R}$ values [@GelmanRubin:1992] below 1.01 [@VehtariEtAl:2020]. Additionally, we assessed the model fit using posterior predictive checks (see the online supplementary material). Overall, apart from some misfit in the outer quantiles of the RT distribution, the DDM could reproduce the data quite accurately and appeared to provide an acceptable account of the data.  
  
### Modeling Results
   A summary of the estimated fixed and random effects parameters can be found in Table \@ref(tab:resFEtable) and \@ref(tab:resREtable), respectively, and a summary table with the random effects correlation parameters in Appendix B.  
  Regarding the fixed effects, our main focus of interest was on $\mu_{\theta_{OR}}$ and $\mu_{\theta_{UT}}$, the overall effects of stimulus originality and utility on the drift rate $\delta$. For $\mu_{\theta_{OR}}$, the posterior mean was $`r FEsummary1[3,1]`$, and the 95% CrI was $[`r FEsummary1[3,3]`,`r FEsummary1[3,4]`]$. For $\mu_{\theta_{UT}}$, the posterior mean was $`r FEsummary1[4,1]`$, and the 95% CrI was $[`r FEsummary1[4,3]`,`r FEsummary1[4,4]`]$. Both posterior means were positive. However, while the 95% credible interval (CrI) of $\mu_{\theta_{OR}}$ did not include zero, the CrI of $\mu_{\theta_{UT}}$ was very close to zero.  
  In general, all estimated posterior means of the remaining fixed effects parameters seem plausible as the CrIs were rather narrow and the parameters lie within a reasonable range (see Table \@ref(tab:resFEtable)). On average, there was no a-priori bias towards the response options 'creative' or 'not creative' (see $\mu_\beta$ in Table \@ref(tab:resFEtable)). This suggests that participants were on average equally likely to choose either of the two response options before stimulus onset. However, the boundary separation, or response caution, was higher than found in most applications of the diffusion model [e.g., @MatzkeWagenmakers:2009, see $\mu_\alpha$ in Table \@ref(tab:resFEtable)]. One explanation for this rather high value is that the RTs in the CON-task were considerably slower than RTs in tasks typically modeled by the diffusion model.  
  We found substantial individual differences in all variability parameters. Notably, the results showed substantial variability across participants in the originality and utility effects on the drift rate. The posterior means of $\sigma_{OR}$ and $\sigma_{UT}$ were $`r REsummary1[2,1]`$ and $`r REsummary1[3,1]`$, respectively. The posterior means and credible intervals of all variability parameters are listed in Table \@ref(tab:resREtable). None of the CrIs included zero suggesting considerable variability across stimuli and across participants.  
   Figures \@ref(fig:plotIndEstimates)A and B visualize this variability in the originality and utility effects on the drift rate by depicting the posterior means of the individual originality slopes $\theta_{{OR}(i)}$ and utility slopes $\theta_{{UT}(i)}$ and their corresponding CrIs in increasing order. The figures show substantial individual differences. Regarding the individual originality effects, there were even `r orig.dr.sums[1,4]` participants with a negative posterior mean (`r round(sum(eff1$Estimate.orig.rating_s < 0)/nrow(eff1)*100, digits = 2)`%). However, the 95%CrI of these estimates included zero. In total, the CrI of `r orig.dr.sums[1,3]` individuals included zero (`r round(sum(eff1$Q2.5.orig.rating_s < 0 & eff1$Q97.5.orig.rating_s > 0)/nrow(eff1)*100, digits = 2)`%), suggesting that, at the very least, for some individuals, the effect of stimulus originality on the drift rate was weaker and for some it was stronger.  
  Participants further differed in their utility slopes. As shown in Figure \@ref(fig:plotIndEstimates)B, for some, the utility effect on the drift was around zero, for some it was positive, and for a few the effect was even negative. Specifically, the majority of the individual CrIs (*n* = `r util.dr.sums[1,3]`; `r round(sum(eff1$Q2.5.util.rating_s < 0 & eff1$Q97.5.util.rating_s > 0)/nrow(eff1)*100, digits = 2)`%) included zero, `r util.dr.sums[1,1]` (`r round(sum(eff1$Q2.5.util.rating_s > 0), digits = 2)/nrow(eff1)*100`%) of them excluded and were above zero, and `r util.dr.sums[1,2]` (`r round(sum(eff1$Q97.5.util.rating_s < 0), digits = 2)/nrow(eff1)*100`%) individual CrIs excluded and were below zero.  
  
 Individual differences also manifested themselves in a negative correlation between the originality and utility slopes. Here the posterior mean of $\rho_{\sigma_{\theta_{OR}}\sigma_{\theta_{UT}}}$ was `r REsummary1[7,1]`, 95%CrI [`r REsummary1[7,3]`, `r REsummary1[7,4]`], and the correlation between the individual originality and utility slopes, based on the posterior means, was $r =$ `r mean(cor.or.ut[,1])`, 95%CrI [`r quantile(cor.or.ut[,1], probs = 0.025)`, `r quantile(cor.or.ut[,1], probs = 0.975)`]`r apa_print(BF.cor.or.ut)$full_result`. It is expected that $r$ is greater than $\rho$ because $\rho_{\sigma_{\theta_{OR}}\sigma_{\theta_{UT}}}$ is a population parameter taking uncertainty into account and $r$ reflects the data in our sample. The greater the individual effect of stimulus originality on the drift rate, the smaller the effect of stimulus utility and vice versa.
 This correlation could also be explained by the substantial negative correlation between the originality and utility ratings for the CON-task stimuli ($r =$ `r mean(cor.orig.util[,"rho"])`). We ruled this out by re-estimating the DDM when excluding the stimuli that contributed the strongest to the negative correlation. Specifically, we excluded the data from 20 items leaving us with CON-task data based on 44 stimuli. Excluding those items reduced the stimulus originality-utility ratings correlation from $r =$ `r mean(cor.orig.util[,"rho"])` to r = -.15. Despite this reduced correlation across stimuli, the negative correlation across originality and utility effects on individual drift rates remained substantial, r = -.49, 95%CrI [-0.67, -0.29] (see supplementary materials). This result suggests that the correlation across effects is not (solely) a function of stimulus characteristics.  
  Figure \@ref(fig:corOrigUtil)A, shows the multivariate, joint posterior distribution of the originality and utility effects and Figure \@ref(fig:corOrigUtil)B the individual posterior means and corresponding standard deviations to visualize this correlation. An overview table of the correlations among all random effects parameters can be found in Table \@ref(tab:resCORtable) in Appendix D. Figure \@ref(fig:corOrigUtil)B further depicts two clusters that are the results from an exploratory k-means cluster analysis: it seems that one cluster comprises individuals with a positive effect of utility and a rather small effect of stimulus originality, and the other one individuals with a stimulus utility effect around zero and a positive effect of originality.   
  
#### CON-task and self-report ratings of originality and utility

  As a plaubility check for our rationale behind the drift rate regression, we examined whether the self-reported importance ratings of originality, innovativeness, utility, and appropriateness corresponded to the originality and utility effects on the drift rate. We summed up the ratings of appropriateness and utility and innovativeness and originality, respectively. There was a positive correlation between participants' importance ratings of originality and the posterior means of their originality slopes, $r =$ `r mean(cor.orrat.or[,"rho"])`, 95%CrI [`r quantile(cor.orrat.or[,"rho"], probs = 0.025)`, `r quantile(cor.orrat.or[,"rho"], probs = 0.975)`]`r apa_print(BF.cor.orrat.or)$full_result` and between their ratings of utility and utility slopes, $r =$ `r mean(cor.utrat.ut[,"rho"])`, 95%CrI [`r quantile(cor.utrat.ut[,"rho"], probs = 0.025)`, `r quantile(cor.utrat.ut[,"rho"], probs = 0.975)`]  `r apa_print(BF.cor.utrat.ut)$full_result`. The more participants indicated that originality was important when determining whether something is creative or not, the greater their influence of stimulus originality on their drift rate. The more they indicated that utility was important, the greater their effect of stimulus utility on their drift rate. There were also negative correlations between the originality importance ratings and the utility slopes, $r =$ `r mean(cor.orrat.ut[,"rho"])`, 95%CrI [`r quantile(cor.orrat.ut[,"rho"], probs = 0.025)`, `r quantile(cor.orrat.ut[,"rho"], probs = 0.975)`]  `r apa_print(BF.cor.orrat.ut)$full_result`, and between the utility ratings and the originality slopes, $r =$ `r mean(cor.utrat.or[,"rho"])`, 95%CrI [`r quantile(cor.utrat.or[,"rho"], probs = 0.025)`, `r quantile(cor.utrat.or[,"rho"], probs = 0.975)`]`r apa_print(BF.cor.utrat.or)$full_result`.  
  
#### CON-task and divergent thinking

  Given the substantial variability in the stimulus originality and utility effects on the drift rate, we explored whether this variability was related to variability in divergent thinking performance as assessed by the AUT. To this end, we computed correlations among the individual posterior means and participants' AUT performance scores. The data cleaning for the AUT task is described in Appendix B.  
  We found a positive correlation between AUT originality scores and the originality slope posterior means, $r =$ `r mean(cor.autor.or[,"rho"])`, 95%CrI [`r quantile(cor.autor.or[,"rho"], probs = 0.025)`, `r quantile(cor.autor.or[,"rho"], probs = 0.975)`] `r apa_print(BF.cor.autor.or)$full_result`, suggesting that the more original the AUT responses, the greater the influence of originality on the drift rate in the CON task. We also found a negative correlation between the posterior means of the utility slopes and participants originality scores, $r =$ `r mean(cor.autor.ut[,"rho"])`, 95%CrI [`r quantile(cor.autor.ut[,"rho"], probs = 0.025)`, `r quantile(cor.autor.ut[,"rho"], probs = 0.975)`]`r apa_print(BF.cor.autor.ut)$full_result`. The more original responses participants produced in the AUT, the smaller their effects of stimulus utility on the drift rate. However, there was no correlation between the AUT utility scores and the stimulus utility effects on the drift rate, $r =$ `r mean(cor.autut.ut[,"rho"])`, 95%CrI [`r quantile(cor.autut.ut[,"rho"], probs = 0.025)`, `r quantile(cor.autut.ut[,"rho"], probs = 0.975)`]  `r apa_print(BF.cor.autut.ut)$full_result`, and also no correlation between AUT utility scores and stimulus originality effects, $r =$ `r mean(cor.autut.or[,"rho"])`, 95%CrI [`r quantile(cor.autut.or[,"rho"], probs = 0.025)`,`r quantile(cor.autut.or[,"rho"], probs = 0.975)`]`r apa_print(BF.cor.autut.or)$full_result`.  
  Since the application of the DDM to creativity is novel and since Study 1 was conducted in a rather exploratory manner, we aimed to assess the robustness of our findings in a second, preregistered Study (https://osf.io/7gt45/). In Study 2, we therefore specified hypotheses based on Study 1’s results as well as previous research and re-fitted the DDM on an independent dataset.

[^w]: For all analyses, we used `r my_citation`.
[^d]: The exact results depended on whether the median of the stimuli's utility ratings was included in the low- or the high-utility group. When the median was assigned to the low-utility group, the evidence for the correlation between originality and RT in the high-utility group was even smaller: $r =$ `r mean(corr_median_split_s1_util_high_excl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s1_util_high_excl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s1_util_high_excl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s1_util_high_excl_median)$full_result`. The evidence for no correlation between originality and RT in the low-utility group was also even smaller to the point where there was practically neither evidence for the presence nor for the absence of a correlation, $r =$ `r mean(corr_median_split_s1_util_low_excl_median[,"rho"])`, 95%CrI [`r quantile(corr_median_split_s1_util_low_excl_median[,"rho"], probs = 0.025)`, `r quantile(corr_median_split_s1_util_low_excl_median[,"rho"], probs = 0.975)`]`r apa_print(bf_corr_median_split_s1_util_low_excl_median)$full_result`    